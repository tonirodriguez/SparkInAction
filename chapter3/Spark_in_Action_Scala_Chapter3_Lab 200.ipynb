{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4828166f",
   "metadata": {},
   "source": [
    "#Â Spark in Action - Chapter 3 Scala Version - Lab 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64af240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.41:4040\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1667056910713)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.concat\n",
       "import org.apache.spark.sql.functions.lit\n",
       "import org.apache.spark.Partition\n",
       "import org.apache.spark.sql.Dataset\n",
       "import org.apache.spark.sql.Row\n",
       "import org.apache.spark.sql.SparkSession\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.concat\n",
    "import org.apache.spark.sql.functions.lit\n",
    "import org.apache.spark.Partition\n",
    "import org.apache.spark.sql.Dataset\n",
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c0a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/29 17:21:59 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@4a8fea7d\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "                .builder\n",
    "                .appName(\"Restaurants in Wake County, NC\")\n",
    "                .master(\"local[*]\")\n",
    "                .getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Right after ingestion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [OBJECTID: string, HSISID: string ... 13 more fields]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Restaurants_in_Wake_County_NC.csv,\n",
    "// stores it in a dataframe\n",
    "var df = spark\n",
    "            .read\n",
    "            .format(\"csv\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .load(\"../net.jgp.books.spark.ch03/data/Restaurants_in_Wake_County_NC.csv\")\n",
    "\n",
    "println(\"*** Right after ingestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7ad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+--------------------+-----------------+--------+------------+-----------+-------------+\n",
      "|OBJECTID|     HSISID|                NAME|            ADDRESS1|ADDRESS2|       CITY|STATE|POSTALCODE|   PHONENUMBER|  RESTAURANTOPENDATE|     FACILITYTYPE|PERMITID|           X|          Y|GEOCODESTATUS|\n",
      "+--------+-----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+--------------------+-----------------+--------+------------+-----------+-------------+\n",
      "|    1001|04092016024|                WABA|2502 1/2 HILLSBOR...|    null|    RALEIGH|   NC|     27607|(919) 833-1710|2011-10-18T00:00:...|       Restaurant|    6952|-78.66818477|35.78783803|            M|\n",
      "|    1002|04092021693|  WALMART DELI #2247|2010 KILDAIRE FAR...|    null|       CARY|   NC|     27518|(919) 852-6651|2011-11-08T00:00:...|       Food Stand|    6953|-78.78211173|35.73717591|            M|\n",
      "|    1003|04092017012|CAROLINA SUSHI &a...|5951-107 POYNER V...|    null|    RALEIGH|   NC|     27616|(919) 981-5835|2015-08-28T00:00:...|       Restaurant|    6961|-78.57030208|35.86511564|            M|\n",
      "|    1004|04092030288|THE CORNER VENEZU...|    7500 RAMBLE WAY |    null|    RALEIGH|   NC|     27616|          null|2015-09-04T00:00:...|Mobile Food Units|    6962|  -78.537511|35.87630712|            M|\n",
      "|    1005|04092015530|        SUBWAY #3726| 12233 CAPITAL BLVD |    null|WAKE FOREST|   NC|27587-6200|(919) 556-8266|2009-12-11T00:00:...|       Restaurant|    6972|-78.54097555|35.98087357|            M|\n",
      "+--------+-----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+--------------------+-----------------+--------+------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- OBJECTID: string (nullable = true)\n",
      " |-- HSISID: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- ADDRESS1: string (nullable = true)\n",
      " |-- ADDRESS2: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- POSTALCODE: string (nullable = true)\n",
      " |-- PHONENUMBER: string (nullable = true)\n",
      " |-- RESTAURANTOPENDATE: string (nullable = true)\n",
      " |-- FACILITYTYPE: string (nullable = true)\n",
      " |-- PERMITID: string (nullable = true)\n",
      " |-- X: string (nullable = true)\n",
      " |-- Y: string (nullable = true)\n",
      " |-- GEOCODESTATUS: string (nullable = true)\n",
      "\n",
      "We have 3440 records.\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "df.printSchema()\n",
    "println(\"We have \" + df.count + \" records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf68b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [datasetId: string, name: string ... 11 more fields]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Let's transform our dataframe\n",
    "df =  df.withColumn(\"county\", lit(\"Wake\"))\n",
    "        .withColumnRenamed(\"HSISID\", \"datasetId\")\n",
    "        .withColumnRenamed(\"NAME\", \"name\")\n",
    "        .withColumnRenamed(\"ADDRESS1\", \"address1\")\n",
    "        .withColumnRenamed(\"ADDRESS2\", \"address2\")\n",
    "        .withColumnRenamed(\"CITY\", \"city\")\n",
    "        .withColumnRenamed(\"STATE\", \"state\")\n",
    "        .withColumnRenamed(\"POSTALCODE\", \"zip\")\n",
    "        .withColumnRenamed(\"PHONENUMBER\", \"tel\")\n",
    "        .withColumnRenamed(\"RESTAURANTOPENDATE\", \"dateStart\")\n",
    "        .withColumnRenamed(\"FACILITYTYPE\", \"type\")\n",
    "        .withColumnRenamed(\"X\", \"geoX\")\n",
    "        .withColumnRenamed(\"Y\", \"geoY\")\n",
    "        .drop(\"OBJECTID\",\"PERMITID\",\"GEOCODESTATUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ca633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [datasetId: string, name: string ... 12 more fields]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn(\"id\",\n",
    "      concat(df.col(\"state\"), lit(\"_\"), df.col(\"county\"), lit(\"_\"), df.col(\"datasetId\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7913a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Dataframe transformed\n",
      "+-----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+--------------------+-----------------+------------+-----------+------+-------------------+\n",
      "|  datasetId|                name|            address1|address2|       city|state|       zip|           tel|           dateStart|             type|        geoX|       geoY|county|                 id|\n",
      "+-----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+--------------------+-----------------+------------+-----------+------+-------------------+\n",
      "|04092016024|                WABA|2502 1/2 HILLSBOR...|    null|    RALEIGH|   NC|     27607|(919) 833-1710|2011-10-18T00:00:...|       Restaurant|-78.66818477|35.78783803|  Wake|NC_Wake_04092016024|\n",
      "|04092021693|  WALMART DELI #2247|2010 KILDAIRE FAR...|    null|       CARY|   NC|     27518|(919) 852-6651|2011-11-08T00:00:...|       Food Stand|-78.78211173|35.73717591|  Wake|NC_Wake_04092021693|\n",
      "|04092017012|CAROLINA SUSHI &a...|5951-107 POYNER V...|    null|    RALEIGH|   NC|     27616|(919) 981-5835|2015-08-28T00:00:...|       Restaurant|-78.57030208|35.86511564|  Wake|NC_Wake_04092017012|\n",
      "|04092030288|THE CORNER VENEZU...|    7500 RAMBLE WAY |    null|    RALEIGH|   NC|     27616|          null|2015-09-04T00:00:...|Mobile Food Units|  -78.537511|35.87630712|  Wake|NC_Wake_04092030288|\n",
      "|04092015530|        SUBWAY #3726| 12233 CAPITAL BLVD |    null|WAKE FOREST|   NC|27587-6200|(919) 556-8266|2009-12-11T00:00:...|       Restaurant|-78.54097555|35.98087357|  Wake|NC_Wake_04092015530|\n",
      "+-----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+--------------------+-----------------+------------+-----------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Shows at most 5 rows from the dataframe\n",
    "println(\"*** Dataframe transformed\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d6066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+-----+---------------+------+---------------+\n",
      "|           name|       city|state|           type|county|             id|\n",
      "+---------------+-----------+-----+---------------+------+---------------+\n",
      "|           WABA|    RALEIGH|   NC|     Restaurant|  Wake|NC_Wake_0409...|\n",
      "|WALMART DELI...|       CARY|   NC|     Food Stand|  Wake|NC_Wake_0409...|\n",
      "|CAROLINA SUS...|    RALEIGH|   NC|     Restaurant|  Wake|NC_Wake_0409...|\n",
      "|THE CORNER V...|    RALEIGH|   NC|Mobile Food ...|  Wake|NC_Wake_0409...|\n",
      "|   SUBWAY #3726|WAKE FOREST|   NC|     Restaurant|  Wake|NC_Wake_0409...|\n",
      "+---------------+-----------+-----+---------------+------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "drop_cols: List[String] = List(address2, zip, tel, dateStart, geoX, geoY, address1, datasetId)\n",
       "dfUsedForBook: org.apache.spark.sql.DataFrame = [name: string, city: string ... 4 more fields]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// for book only\n",
    "val drop_cols=List(\"address2\",\"zip\",\"tel\",\"dateStart\",\n",
    "              \"geoX\",\"geoY\",\"address1\",\"datasetId\")\n",
    "val dfUsedForBook = df.drop(drop_cols:_*)\n",
    "dfUsedForBook.show(5, 15)\n",
    "// end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcbf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datasetId: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address1: string (nullable = true)\n",
      " |-- address2: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- tel: string (nullable = true)\n",
      " |-- dateStart: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- geoX: string (nullable = true)\n",
      " |-- geoY: string (nullable = true)\n",
      " |-- county: string (nullable = false)\n",
      " |-- id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c6877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Looking at partitions\n",
      "Partition count before repartition: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "partitions: Array[org.apache.spark.Partition] = Array(FilePartition(0,[Lorg.apache.spark.sql.execution.datasources.PartitionedFile;@5d3be711))\n",
       "partitionCount: Int = 1\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"*** Looking at partitions\")\n",
    "val partitions = df.rdd.partitions\n",
    "val partitionCount = partitions.length\n",
    "println(\"Partition count before repartition: \" + partitionCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition count after repartition: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [datasetId: string, name: string ... 12 more fields]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.repartition(4)\n",
    "println(\"Partition count after repartition: \" + df.rdd.partitions.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962341ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ee767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
