{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34b2fc3",
   "metadata": {},
   "source": [
    "#Â Spark in Action - Chapter 3 Python Version - Lab 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b21234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/29 17:20:48 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Union of two dataframes\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel('warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_file_path(path, filename):\n",
    "    # To get absolute path for a given filename\n",
    "    current_dir = os.getcwd() #os.path.dirname(__file__)\n",
    "    relative_path = \"{}{}\".format(path, filename)\n",
    "    absolute_file_path = os.path.join(current_dir, relative_path)\n",
    "    return absolute_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'Restaurants_in_Wake_County_NC.csv'\n",
    "path1 = '../net.jgp.books.spark.ch03/data/'\n",
    "absolute_file_path1 = get_absolute_file_path(path1, filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'Restaurants_in_Durham_County_NC.json'\n",
    "path2 = '../net.jgp.books.spark.ch03/data/'\n",
    "absolute_file_path2 = get_absolute_file_path(path2, filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(path=absolute_file_path1, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b604b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.json(absolute_file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Builds the dataframe containing the Wake county restaurants\n",
    "*\n",
    "* @return A dataframe\n",
    "\"\"\"\n",
    "def build_wake_restaurants_dataframe(df):\n",
    "    drop_cols = [\"OBJECTID\", \"GEOCODESTATUS\", \"PERMITID\"]\n",
    "    df = df.withColumn(\"county\", F.lit(\"Wake\")) \\\n",
    "        .withColumnRenamed(\"HSISID\", \"datasetId\") \\\n",
    "        .withColumnRenamed(\"NAME\", \"name\") \\\n",
    "        .withColumnRenamed(\"ADDRESS1\", \"address1\") \\\n",
    "        .withColumnRenamed(\"ADDRESS2\", \"address2\") \\\n",
    "        .withColumnRenamed(\"CITY\", \"city\") \\\n",
    "        .withColumnRenamed(\"STATE\", \"state\") \\\n",
    "        .withColumnRenamed(\"POSTALCODE\", \"zip\") \\\n",
    "        .withColumnRenamed(\"PHONENUMBER\", \"tel\") \\\n",
    "        .withColumnRenamed(\"RESTAURANTOPENDATE\", \"dateStart\") \\\n",
    "        .withColumn(\"dateEnd\", F.lit(None)) \\\n",
    "        .withColumnRenamed(\"FACILITYTYPE\", \"type\") \\\n",
    "        .withColumnRenamed(\"X\", \"geoX\") \\\n",
    "        .withColumnRenamed(\"Y\", \"geoY\") \\\n",
    "        .drop(\"OBJECTID\", \"GEOCODESTATUS\", \"PERMITID\")\n",
    "\n",
    "    df = df.withColumn(\"id\",\n",
    "                       F.concat(F.col(\"state\"), F.lit(\"_\"),\n",
    "                                F.col(\"county\"), F.lit(\"_\"),\n",
    "                                F.col(\"datasetId\")))\n",
    "    # I left the following line if you want to play with repartitioning\n",
    "    # df = df.repartition(4);\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Builds the dataframe containing the Durham county restaurants\n",
    "*\n",
    "* @return A dataframe\n",
    "\"\"\"\n",
    "def build_durham_restaurants_dataframe(df):\n",
    "    drop_cols = [\"fields\", \"geometry\", \"record_timestamp\", \"recordid\"]\n",
    "    df =  df.withColumn(\"county\", F.lit(\"Durham\")) \\\n",
    "            .withColumn(\"datasetId\", F.col(\"fields.id\")) \\\n",
    "            .withColumn(\"name\", F.col(\"fields.premise_name\")) \\\n",
    "            .withColumn(\"address1\", F.col(\"fields.premise_address1\")) \\\n",
    "            .withColumn(\"address2\", F.col(\"fields.premise_address2\")) \\\n",
    "            .withColumn(\"city\", F.col(\"fields.premise_city\")) \\\n",
    "            .withColumn(\"state\", F.col(\"fields.premise_state\")) \\\n",
    "            .withColumn(\"zip\", F.col(\"fields.premise_zip\")) \\\n",
    "            .withColumn(\"tel\", F.col(\"fields.premise_phone\")) \\\n",
    "            .withColumn(\"dateStart\", F.col(\"fields.opening_date\")) \\\n",
    "            .withColumn(\"dateEnd\", F.col(\"fields.closing_date\")) \\\n",
    "            .withColumn(\"type\", F.split(F.col(\"fields.type_description\"), \" - \").getItem(1)) \\\n",
    "            .withColumn(\"geoX\", F.col(\"fields.geolocation\").getItem(0)) \\\n",
    "            .withColumn(\"geoY\", F.col(\"fields.geolocation\").getItem(1)) \\\n",
    "            .drop(*drop_cols)\n",
    "\n",
    "    df = df.withColumn(\"id\",\n",
    "                       F.concat(F.col(\"state\"), F.lit(\"_\"),\n",
    "                                F.col(\"county\"), F.lit(\"_\"),\n",
    "                                F.col(\"datasetId\")))\n",
    "    # I left the following line if you want to play with repartitioning\n",
    "    # df = df.repartition(4);\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Performs the union between the two dataframes.\n",
    "*\n",
    "* @param df1 Left Dataframe to union on\n",
    "* @param df2 Right Dataframe to union from\n",
    "\"\"\"\n",
    "def combineDataframes(df1, df2):\n",
    "    df = df1.unionByName(df2)\n",
    "    df.show(5)\n",
    "    df.printSchema()\n",
    "    logging.warning(\"We have {} records.\".format(df.count()))\n",
    "    partition_count = df.rdd.getNumPartitions()\n",
    "    logging.warning(\"Partition count: {}\".format(partition_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeRestaurantsDf = build_wake_restaurants_dataframe(df1)\n",
    "durhamRestaurantsDf = build_durham_restaurants_dataframe(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a7ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+-------------------+-----------------+------------+-----------+------+-------+------------------+\n",
      "| datasetId|                name|            address1|address2|       city|state|       zip|           tel|          dateStart|             type|        geoX|       geoY|county|dateEnd|                id|\n",
      "+----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+-------------------+-----------------+------------+-----------+------+-------+------------------+\n",
      "|4092016024|                WABA|2502 1/2 HILLSBOR...|    null|    RALEIGH|   NC|     27607|(919) 833-1710|2011-10-18 02:00:00|       Restaurant|-78.66818477|35.78783803|  Wake|   null|NC_Wake_4092016024|\n",
      "|4092021693|  WALMART DELI #2247|2010 KILDAIRE FAR...|    null|       CARY|   NC|     27518|(919) 852-6651|2011-11-08 01:00:00|       Food Stand|-78.78211173|35.73717591|  Wake|   null|NC_Wake_4092021693|\n",
      "|4092017012|CAROLINA SUSHI &a...|5951-107 POYNER V...|    null|    RALEIGH|   NC|     27616|(919) 981-5835|2015-08-28 02:00:00|       Restaurant|-78.57030208|35.86511564|  Wake|   null|NC_Wake_4092017012|\n",
      "|4092030288|THE CORNER VENEZU...|    7500 RAMBLE WAY |    null|    RALEIGH|   NC|     27616|          null|2015-09-04 02:00:00|Mobile Food Units|  -78.537511|35.87630712|  Wake|   null|NC_Wake_4092030288|\n",
      "|4092015530|        SUBWAY #3726| 12233 CAPITAL BLVD |    null|WAKE FOREST|   NC|27587-6200|(919) 556-8266|2009-12-11 01:00:00|       Restaurant|-78.54097555|35.98087357|  Wake|   null|NC_Wake_4092015530|\n",
      "+----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+-------------------+-----------------+------------+-----------+------+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- datasetId: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address1: string (nullable = true)\n",
      " |-- address2: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- tel: string (nullable = true)\n",
      " |-- dateStart: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- geoX: double (nullable = true)\n",
      " |-- geoY: double (nullable = true)\n",
      " |-- county: string (nullable = false)\n",
      " |-- dateEnd: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:We have 5903 records.\n",
      "WARNING:root:Partition count: 2\n"
     ]
    }
   ],
   "source": [
    "combineDataframes(wakeRestaurantsDf, durhamRestaurantsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c748d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
